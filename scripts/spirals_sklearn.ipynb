{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateMasterSpiralDF(dirName=\".\"):\n",
    "    \"\"\"CreateMasterSpiralDF(dirName) where dirName is the directory name of the .spiral files,\n",
    "       output pandas dataframe of all spiral files header data and filenames\"\"\"\n",
    "    assert isinstance(dirName, str), \"The 'dirName' argument must be a string!\"\n",
    "    fileNames = [dirName+'/'+i for i in listdir(dirName) if i[-7:] == '.spiral']\n",
    "    \n",
    "    if len(fileNames)==0:\n",
    "        print(\"No '.spiral' files found in directory '\"+dirName+\"'.\")\n",
    "        return\n",
    "    \n",
    "    D = {\"file_name\" : []}\n",
    "    for index,name in enumerate(fileNames):\n",
    "        f = open(name,'r')\n",
    "        for i in range(2): colNames = f.readline().split()\n",
    "        if index == 0:\n",
    "            for colName in colNames:\n",
    "                D[colName] = []\n",
    "        D[\"file_name\"].append(name)\n",
    "        simParams = f.readline().split()\n",
    "        for colIndex,colName in enumerate(colNames):\n",
    "            D[colName].append(float(simParams[colIndex]))\n",
    "        f.close()\n",
    "    df = pd.DataFrame(D)\n",
    "    return df\n",
    "\n",
    "def CreateSpiralDF(fileName):\n",
    "    \"\"\"CreateSpiralDF(fileName) where fileName is the name of a '.spiral' analysis file,\n",
    "       outputs pandas dataframe of time series data\"\"\"\n",
    "    assert isinstance(fileName,str), \"The 'fileName' argument must be a string!\"\n",
    "    try:\n",
    "        f = open(fileName,'r')\n",
    "    except:\n",
    "        print(\"Could not open file '\" + fileName + \"'.\")\n",
    "        return\n",
    "    for i in range(4): colNames = f.readline().split()\n",
    "    D = {}\n",
    "    for colName in colNames:\n",
    "        D[colName] = []\n",
    "    for line in f:\n",
    "        line = line.split()\n",
    "        if (len(line) != len(colNames)):\n",
    "            break # early exit due to early simulation termination\n",
    "        for colIndex, colName in enumerate(colNames):\n",
    "            D[colName].append(float(line[colIndex]))\n",
    "    f.close()\n",
    "    df = pd.DataFrame(D)\n",
    "    return df\n",
    "\n",
    "def GetSpiralFrequencies(masterDF):\n",
    "    maxTime = int(masterDF[\"nsteps\"][0]/masterDF[\"nspec\"][0])-1\n",
    "    freqs = pd.Series(np.zeros(len(masterDF.index)))\n",
    "    for i in masterDF.index:\n",
    "        df=CreateSpiralDF(masterDF.iloc[i][\"file_name\"])\n",
    "        if not (df[\"time\"].iloc[-1] < maxTime):\n",
    "            freqs[i] = GetSpiralFrequency(df,maxTime)\n",
    "    masterDF[\"spiral_frequency\"] = freqs\n",
    "    \n",
    "def GetBendingEnergies(masterDF):\n",
    "    maxTime = int(masterDF[\"nsteps\"][0]/masterDF[\"nspec\"][0])-1\n",
    "    ebend = pd.Series(np.zeros(len(masterDF.index)))\n",
    "    for i in masterDF.index:\n",
    "        df=CreateSpiralDF(masterDF.iloc[i][\"file_name\"])\n",
    "        if not (df[\"time\"].iloc[-1] < maxTime) and masterDF.iloc[i][\"spiral_frequency\"]:\n",
    "            ebend[i] = df[\"E_bend\"].iloc[-1]\n",
    "        else:\n",
    "            ebend[i] = None\n",
    "    masterDF[\"E_bend\"] = ebend\n",
    "\n",
    "def GetSpiralFrequency(df,maxTime):\n",
    "    assert isinstance(df,pd.DataFrame),\"df needs to be pandas DataFrame type\"\n",
    "    N=int(len(df[\"time\"])/2) #num of gridpoints\n",
    "    delta=1\n",
    "    time = np.array(df[\"time\"][:N])\n",
    "    z = np.array(df[\"tip_z_proj\"][N:])\n",
    "    # If we have odd time, make z and time same size\n",
    "    if len(time)!=len(z):\n",
    "        z = np.array(df[\"tip_z_proj\"][N+1:])\n",
    "    # Zero pad data, assuming spiral continues indefinitely\n",
    "    padding=int(2**17)\n",
    "    yf=np.fft.fft(z,n=padding)\n",
    "    xf=np.fft.fftfreq(padding,d=delta)\n",
    "    freq = xf[int(np.argmax(2.0/padding * np.abs(yf[0:int(padding/2)])))]\n",
    "    # If our period lasts longer than a simulation, then return freq=0 (assume no spiral) \n",
    "    if freq > 3.0/maxTime:\n",
    "        return freq\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def PlotSpiralFrequencies(masterDF):\n",
    "    maxTime = int(masterDF[\"nsteps\"][0]/masterDF[\"nspec\"][0])-1\n",
    "    for i in masterDF.index:\n",
    "        df=CreateSpiralDF(masterDF.iloc[i][\"file_name\"])\n",
    "        # If we exited early, spiral did not form\n",
    "        if not (df[\"time\"].iloc[-1] < maxTime):\n",
    "            PlotSpiralFrequency(df,maxTime)\n",
    "\n",
    "def PlotSpiralFrequency(df,maxTime):\n",
    "    assert isinstance(df,pd.DataFrame),\"df needs to be pandas DataFrame type\"\n",
    "    assert isinstance(maxTime, (float,int)), \"maxTime needs to be a float or int\"\n",
    "    N=len(df[\"time\"])/2 #num of gridpoints\n",
    "    delta=1\n",
    "    time = np.array(df[\"time\"][:N])\n",
    "    z = np.array(df[\"tip_z_proj\"][N:])\n",
    "    # If we have odd time, make z and time same size\n",
    "    if len(time)!=len(z):\n",
    "        z = np.array(df[\"tip_z_proj\"][N+1:])\n",
    "    # Zero pad data, assuming spiral continues indefinitely\n",
    "    padding=int(2**17)\n",
    "    yf=np.fft.fft(z,n=padding)\n",
    "    xf=np.fft.fftfreq(padding,d=delta)\n",
    "    freq = xf[int(np.argmax(2.0/padding * np.abs(yf[0:padding/2])))]\n",
    "    if freq < 1.0/maxTime:\n",
    "        return\n",
    "    guess_phase=0\n",
    "    optimize_func = lambda phase: np.sin(2*np.pi*freq*(time+phase))-z\n",
    "    est_phase = leastsq(optimize_func, guess_phase)[0]\n",
    "    est_data = np.sin(2*np.pi*freq*(time+est_phase))\n",
    "    f, ax = plt.subplots(2)\n",
    "    ax[0].set_title(r\"$f_{max} = $\" + str(freq))\n",
    "    ax[0].plot(xf,yf.real,xf,yf.imag)\n",
    "    ax[0].set_xlim(0,2*freq)\n",
    "    ax[0].set_xlabel(\"frequency\")\n",
    "    ax[0].set_ylabel(\"fft signal\")\n",
    "    ax[0].legend([\"real\",\"imag\"],loc=1)\n",
    "    ax[1].plot(time,z,'k-',time,est_data,'r--')\n",
    "    ax[1].set_xlabel(\"sim time\")\n",
    "    ax[1].set_title(\"Filament tip orientation \"+r'$U_Z$')\n",
    "    ax[1].set_ylabel(r'$U_Z$')\n",
    "    ax[1].set_xlim(0,min(8.0/freq,time[-1]))\n",
    "    ax[1].legend(['Data','LS Fit'],loc=1)\n",
    "    f.subplots_adjust(hspace=0.7)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "def PlotFrequencyContour(masterDF):\n",
    "    df=masterDF\n",
    "    x1 = np.linspace(df['driving'].min(), df['driving'].max(), len(df['driving'].unique()))\n",
    "    y1 = np.linspace(df['persistence_length'].min(), df['persistence_length'].max(), len(df['persistence_length'].unique()))\n",
    "    x2, y2 = np.meshgrid(x1, y1)\n",
    "    # Interpolate unstructured D-dimensional data.\n",
    "    z2 = griddata((df['driving'], df['persistence_length']), df['spiral_frequency'], (x2, y2),method='linear')\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca()\n",
    "    surf = ax.contourf(x2, y2, z2, rstride=1, cstride=1, cmap=cm.coolwarm,\n",
    "                           linewidth=0, antialiased=False)\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    plt.title('Spiral frequency, L=50')\n",
    "    plt.xlabel(\"Driving\")\n",
    "    plt.ylabel(\"Persistence Length\")\n",
    "    plt.ylim(0,8000)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "def PlotEnergyContour(masterDF):\n",
    "    df=masterDF\n",
    "    x1 = np.linspace(df['driving'].min(), df['driving'].max(), len(df['driving'].unique()))\n",
    "    y1 = np.linspace(df['persistence_length'].min(), df['persistence_length'].max(), len(df['persistence_length'].unique()))\n",
    "    x2, y2 = np.meshgrid(x1, y1)\n",
    "    # Interpolate unstructured D-dimensional data.\n",
    "    z2 = griddata((df['driving'], df['persistence_length']), df['E_bend'], (x2, y2),method='linear')\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca()\n",
    "    surf = ax.contourf(x2, y2, z2, rstride=1, cstride=1, cmap=cm.coolwarm,\n",
    "                           linewidth=0, antialiased=False)\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    plt.title('Bending Energy, L=50')\n",
    "    plt.xlabel(\"Driving\")\n",
    "    plt.ylabel(\"Persistence Length\")\n",
    "    plt.ylim(0,8000)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def GetSpiralBool(masterDF):\n",
    "    spirals = pd.Series(np.zeros(len(masterDF.index)))\n",
    "    for i in masterDF.index:\n",
    "        if masterDF.iloc[i][\"spiral_frequency\"] > 0:\n",
    "            spirals[i] = 1\n",
    "    masterDF[\"spiral\"] = spirals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next four cells are raw text and will not be evaluated until the cells are converted back to code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "masterDF = CreateMasterSpiralDF('spiral_t0')\n",
    "GetSpiralFrequencies(masterDF)\n",
    "GetBendingEnergies(masterDF)\n",
    "GetSpiralBool(masterDF)\n",
    "masterDF.to_pickle('spiral_t0.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "masterDF = CreateMasterSpiralDF('diameter_tests')\n",
    "GetSpiralFrequencies(masterDF)\n",
    "GetBendingEnergies(masterDF)\n",
    "GetSpiralBool(masterDF)\n",
    "masterDF.to_pickle('master_spiral_diameter.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "masterDF = CreateMasterSpiralDF('spiral_random')\n",
    "GetSpiralFrequencies(masterDF)\n",
    "GetBendingEnergies(masterDF)\n",
    "GetSpiralBool(masterDF)\n",
    "masterDF.to_pickle('master_spiral_random.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "masterDF = CreateMasterSpiralDF('spiral_fixed_dr')\n",
    "GetSpiralFrequencies(masterDF)\n",
    "GetBendingEnergies(masterDF)\n",
    "GetSpiralBool(masterDF)\n",
    "masterDF.to_pickle('master_spiral_fixed_dr.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "masterDF = CreateMasterSpiralDF('spiral_fixed_lp')\n",
    "GetSpiralFrequencies(masterDF)\n",
    "GetBendingEnergies(masterDF)\n",
    "GetSpiralBool(masterDF)\n",
    "masterDF.to_pickle('master_spiral_fixed_lp.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "masterDF = CreateMasterSpiralDF('spiral_fixed_ar')\n",
    "GetSpiralFrequencies(masterDF)\n",
    "GetBendingEnergies(masterDF)\n",
    "GetSpiralBool(masterDF)\n",
    "masterDF.to_pickle('master_spiral_fixed_ar.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "masterDF = CreateMasterSpiralDF('spiral_fixed_ar')\n",
    "GetSpiralFrequencies(masterDF)\n",
    "GetBendingEnergies(masterDF)\n",
    "GetSpiralBool(masterDF)\n",
    "masterDF.to_pickle('master_spiral_fixed_ar_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start here!\n",
    "\n",
    "df_3d = pd.read_pickle('master_spiral_random.pkl')\n",
    "#df_3d = pd.read_pickle('master_spiral_diameter.pkl')\n",
    "df_fixed_dr = pd.read_pickle('master_spiral_fixed_dr.pkl')\n",
    "df_fixed_lp = pd.read_pickle('master_spiral_fixed_lp.pkl') \n",
    "df_fixed_ar = pd.read_pickle('master_spiral_fixed_ar.pkl')\n",
    "df_fixed_ar2 = pd.read_pickle('master_spiral_fixed_ar_2.pkl')\n",
    "df_seglength = pd.read_pickle('master_spiral_seglength.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = ['length','persistence_length','driving']\n",
    "df_3d_poly  = df_3d[feature_names]\n",
    "length2 = df_3d_poly.length.apply(lambda x: x**2)\n",
    "lplen = df_3d_poly.persistence_length / df_3d_poly.length\n",
    "lendr = df_3d_poly.length * df_3d_poly.driving\n",
    "df_3d_poly['length^2'] = length2\n",
    "df_3d_poly['aspect_ratio'] = df_3d_poly.length/1.5\n",
    "df_3d_poly['second_moment'] = df_3d_poly.length*1.5\n",
    "df_3d_poly['lp/len'] = lplen\n",
    "df_3d_poly['len*dr'] = lendr\n",
    "df_3d_poly['logl'] = np.log(df_3d_poly.length)\n",
    "#df_3d_poly = pd.concat([df_3d_poly,pd.DataFrame([length2,lenlp,lendr])])\n",
    "df_3d_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_3d.length.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tempdf=df_3d[df_3d['length']>100]\n",
    "#tempdf=tempdf[tempdf['driving']>50]\n",
    "#df_3d=df_3d.drop(df_3d.index[tempdf[tempdf['spiral']==0].index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = ['lp/len','len*dr','logl','aspect_ratio']\n",
    "target_name = 'spiral'\n",
    "X = np.array(df_3d_poly[feature_names])\n",
    "y = np.array(df_3d[target_name])\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "#poly = PolynomialFeatures(2,False,False)\n",
    "#X=poly.fit_transform(X)\n",
    "param_grid = dict(penalty=[\"l1\",'l2'],C=[1,10,100,1000,10000,1e5,1e6,1e7,1e8])\n",
    "grid = GridSearchCV(logreg, param_grid, cv=10, scoring='accuracy')\n",
    "grid.fit(X,y)\n",
    "print(\"Best logistic regression accuracy: \" + str(grid.best_score_))\n",
    "best = grid.best_params_\n",
    "print(\"Best parameters: \" + str(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = ['lp/len','len*dr','length']\n",
    "target_name = 'spiral'\n",
    "X = np.array(df_3d_poly[feature_names])\n",
    "y = np.array(df_3d[target_name])\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "#poly = PolynomialFeatures(2,False,False)\n",
    "#X=poly.fit_transform(X)\n",
    "param_grid = dict(penalty=[\"l1\",'l2'],C=[1,10,100,1000,10000,1e5,1e6,1e7,1e8])\n",
    "grid = GridSearchCV(logreg, param_grid, cv=10, scoring='accuracy')\n",
    "grid.fit(X,y)\n",
    "print(\"Best logistic regression accuracy: \" + str(grid.best_score_))\n",
    "best = grid.best_params_\n",
    "print(\"Best parameters: \" + str(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(penalty=best['penalty'],C=best['C'],max_iter=200)\n",
    "logreg.fit(X,y)\n",
    "coeff = logreg.coef_[0]\n",
    "intercept = logreg.intercept_[0]\n",
    "print(coeff)\n",
    "print(intercept)\n",
    "#coeff = [i if abs(i) > 1e-3 else 0 for i in coeff]\n",
    "#print coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the decision boundary surface\n",
    "pts = 100 # num mesh points\n",
    "# Set limits for our three parameters\n",
    "x1_min, x1_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "x2_min, x2_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "x3_min, x3_max = X[:, 2].min() - .5, X[:, 2].max() + .5\n",
    "XX,YY = np.meshgrid(np.linspace(x1_min,x1_max,pts),np.linspace(x2_min,x2_max,pts))\n",
    "ZZ = - ( intercept + coeff[0] * XX + coeff[1] * YY) / coeff[2]\n",
    "#ZZ = - ( intercept + coeff[0] * XX + coeff[1] * YY + coeff[3] * XX*XX) / (coeff[2] + coeff[5]*XX)\n",
    "#ZZ = (-coeff[2]-coeff[5]*XX-coeff[7]*YY + np.sqrt((coeff[2]+coeff[5]*XX+coeff[7]*YY)**2-4*coeff[8]*(intercept + coeff[0]*XX + coeff[3]*XX**2 + coeff[1]*YY + coeff[4]* XX*YY + coeff[6]*YY**2)))/(2*coeff[8])\n",
    "# Plot the decision boundary\n",
    "#coeff[3]=0\n",
    "#coeff[4]=0\n",
    "#coeff[5]=0\n",
    "#ZZ = -(intercept + coeff[0] * XX + coeff[1] * YY )/(coeff[2] + coeff[3]* XX)\n",
    "\n",
    "plt3d = plt.figure().gca(projection='3d')\n",
    "plt3d.plot_surface(XX,YY,ZZ,alpha=0.1)\n",
    "\n",
    "# Plot the training points\n",
    "ax = plt.gca()\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:,2], c=-y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "#ax.scatter(X[0,0],X[0,1],X[0,2],c='k',edgecolors='k')\n",
    "#print(y[0])\n",
    "ax.set_xlabel(r'$L_p/L$ ' + \"ratio\",labelpad=10)\n",
    "ax.set_ylabel(r'Driving Force (pN)',labelpad=10)\n",
    "ax.set_zlabel(\"Aspect Ratio\",labelpad=10)\n",
    "ticks = ticker.FuncFormatter(lambda y, pos: '{0:g}'.format(y*0.16))\n",
    "ax.yaxis.set_major_formatter(ticks)\n",
    "ax.set_xlim(x1_min,x1_max)\n",
    "ax.set_ylim(x2_min,x2_max)\n",
    "ax.set_zlim(x3_min,x3_max)\n",
    "ax.set_title('Spool Success (blue) vs Failure (red) at T=0')#,y=0.1)\n",
    "ax.title.set_fontsize(20)\n",
    "ax.xaxis.label.set_fontsize(15)\n",
    "ax.yaxis.label.set_fontsize(15)\n",
    "ax.zaxis.label.set_fontsize(15)\n",
    "#plt.legend(['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driving = np.unique(df_fixed_dr['driving'])\n",
    "assert len(driving)==1\n",
    "driving = driving[0]\n",
    "per_len = np.unique(df_fixed_lp['persistence_length'])\n",
    "assert len(per_len)==1\n",
    "per_len = per_len[0]\n",
    "aspect_ratio = np.unique(df_fixed_ar['length'])\n",
    "assert len(aspect_ratio)==4\n",
    "#aspect_ratio = aspect_ratio[0]\n",
    "aspect_ratio2 = np.unique(df_fixed_ar2['length'])\n",
    "assert len(aspect_ratio2)==1\n",
    "aspect_ratio2 = aspect_ratio2[0]\n",
    "print(\"Fixed driving: \" + str(driving))\n",
    "print(\"Fixed persistence length: \" + str(per_len))\n",
    "print(\"Fixed aspect ratios: \" + str(aspect_ratio))\n",
    "print(\"New fixed AR: \" + str(aspect_ratio2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding length^2 and length*driving terms to dataframes\n",
    "df_fixed_dr['len*dr'] = df_fixed_dr.length * df_fixed_dr.driving\n",
    "df_fixed_lp['len*dr'] = df_fixed_lp.length * df_fixed_lp.driving\n",
    "df_fixed_ar['len*dr'] = df_fixed_ar.length * df_fixed_ar.driving\n",
    "df_fixed_ar2['len*dr'] = df_fixed_ar2.length * df_fixed_ar2.driving\n",
    "df_fixed_dr['logl'] = np.log(df_fixed_dr.length)\n",
    "df_fixed_lp['logl'] = np.log(df_fixed_lp.length)\n",
    "df_fixed_ar['logl'] = np.log(df_fixed_ar.length)\n",
    "df_fixed_ar2['logl'] = np.log(df_fixed_ar2.length)\n",
    "df_fixed_dr['lp/len'] = df_fixed_dr.persistence_length / df_fixed_dr.length\n",
    "df_fixed_lp['lp/len'] = df_fixed_lp.persistence_length / df_fixed_lp.length\n",
    "df_fixed_ar['lp/len'] = df_fixed_ar.persistence_length / df_fixed_ar.length\n",
    "df_fixed_ar2['lp/len'] = df_fixed_ar2.persistence_length / df_fixed_ar2.length\n",
    "aspect_ratio2 = 60.0\n",
    "df_ar = [df_fixed_ar[df_fixed_ar.length == aspect_ratio[i]] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ar_index = 1\n",
    "X_dr = np.array(df_fixed_dr[['logl','persistence_length']])\n",
    "y_dr = np.array(df_fixed_dr['spiral'])\n",
    "X_lp = np.array(df_fixed_lp[['logl','driving']])\n",
    "y_lp = np.array(df_fixed_lp['spiral'])\n",
    "X_ar = np.array(df_ar[ar_index][['persistence_length','driving']])\n",
    "y_ar = np.array(df_ar[ar_index]['spiral'])\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "def bounds(X,i):\n",
    "    return X[:, i].min() - .5, X[:, i].max() + .5\n",
    "\n",
    "x1_min, x1_max = bounds(X_dr,0)\n",
    "x2_min, x2_max = bounds(X_dr,1)\n",
    "x3_min, x3_max = bounds(X_lp,0)\n",
    "x4_min, x4_max = bounds(X_lp,1)\n",
    "x5_min, x5_max = bounds(X_ar,0)\n",
    "x6_min, x6_max = bounds(X_ar,1)\n",
    " \n",
    "XX_dr,YY_dr = np.meshgrid(np.linspace(x1_min,x1_max,100),np.linspace(x2_min,x2_max,100))\n",
    "ZZ_dr = logreg.predict(np.c_[YY_dr.ravel()/XX_dr.ravel(), XX_dr.ravel()*driving,XX_dr.ravel()])\n",
    "ZZ_dr = logreg.predict(np.c_[YY_dr.ravel()/XX_dr.ravel(), XX_dr.ravel()*driving,XX_dr.ravel()])\n",
    "#ZZ_dr = logreg.predict(np.c_[XX_dr.ravel(), YY_dr.ravel(),np.ones(XX_dr.ravel().shape)*driving,XX_dr.ravel()*XX_dr.ravel(),XX_dr.ravel()*YY_dr.ravel(),XX_dr.ravel()*driving])\n",
    "#ZZ_dr = logreg.predict(np.c_[XX_dr.ravel(), YY_dr.ravel(),np.ones(XX_dr.ravel().shape)*driving,XX_dr.ravel()*driving])\n",
    "ZZ_dr = ZZ_dr.reshape(XX_dr.shape)\n",
    "\n",
    "XX_lp,YY_lp = np.meshgrid(np.linspace(x3_min,x3_max,100),np.linspace(x4_min,x4_max,100))\n",
    "ZZ_lp = logreg.predict(np.c_[per_len/XX_lp.ravel(), XX_lp.ravel()*YY_lp.ravel(),XX_lp.ravel()])\n",
    "#ZZ_lp = logreg.predict(np.c_[XX_lp.ravel(),np.ones(XX_lp.ravel().shape)*per_len, YY_lp.ravel(),XX_lp.ravel()*XX_lp.ravel(),XX_lp.ravel()*per_len,XX_lp.ravel()*YY_lp.ravel()])\n",
    "#ZZ_lp = logreg.predict(np.c_[XX_lp.ravel(),np.ones(XX_lp.ravel().shape)*per_len, YY_lp.ravel(),XX_lp.ravel()*YY_lp.ravel()])\n",
    "ZZ_lp = ZZ_lp.reshape(XX_lp.shape)\n",
    "\n",
    "XX_ar,YY_ar = np.meshgrid(np.linspace(x5_min,x5_max,100),np.linspace(x6_min,x6_max,100))\n",
    "ZZ_ar = logreg.predict(np.c_[XX_ar.ravel()/aspect_ratio[ar_index], YY_ar.ravel()*aspect_ratio[ar_index],np.ones(XX_ar.ravel().shape)*aspect_ratio[ar_index]])\n",
    "\n",
    "#ZZ_ar = logreg.predict(np.c_[np.ones(XX_ar.ravel().shape)*aspect_ratio, XX_ar.ravel(), YY_ar.ravel(),np.ones(XX_ar.ravel().shape)*aspect_ratio*aspect_ratio,aspect_ratio*XX_ar.ravel(),aspect_ratio*YY_ar.ravel()])\n",
    "#ZZ_ar = logreg.predict(np.c_[np.ones(XX_ar.ravel().shape)*aspect_ratio, XX_ar.ravel(), YY_ar.ravel(),aspect_ratio*YY_ar.ravel()])\n",
    "ZZ_ar = ZZ_ar.reshape(XX_ar.shape)\n",
    "\n",
    "fig, (ax0,ax1,ax2) = plt.subplots(1,3,figsize=(8,4),dpi=80)\n",
    "\n",
    "ax0.pcolormesh(XX_ar,YY_ar,ZZ_ar, cmap=plt.cm.Paired, alpha=0.2)\n",
    "ax0.scatter(X_ar[:,0],X_ar[:,1], c=y_ar, edgecolors='k', cmap=plt.cm.Paired)\n",
    "ax0.set_xlabel('Persistence Length (mm)',fontsize=15)\n",
    "#ax0.ticklabel_format(style='sci',axis='both',scilimits=(0,0))\n",
    "ticks = ticker.FuncFormatter(lambda y, pos: '{0:g}'.format(y*25/1000/1000))\n",
    "ax0.xaxis.set_major_formatter(ticks)\n",
    "ax0.set_ylabel('Driving (pN/nm)',fontsize=15)\n",
    "ticks = ticker.FuncFormatter(lambda y, pos: '{0:g}'.format(y*0.0064))\n",
    "ax0.yaxis.set_major_formatter(ticks)\n",
    "ax0.set_title(\"Aspect ratio fixed, \"+r'$L/d = 60$',fontsize=16,y=0.9)\n",
    "\n",
    "ax1.pcolormesh(XX_dr,YY_dr,ZZ_dr, cmap=plt.cm.Paired, alpha=0.2)\n",
    "ax1.scatter(X_dr[:,0],X_dr[:,1], c=y_dr, edgecolors='k', cmap=plt.cm.Paired)\n",
    "ax1.set_xlabel('Aspect Ratio',fontsize=15)\n",
    "ax1.set_ylabel('Persistence Length (mm)',fontsize=15)\n",
    "ticks = ticker.FuncFormatter(lambda y, pos: '{0:g}'.format(y*25/1000/1000))\n",
    "ax1.yaxis.set_major_formatter(ticks)\n",
    "ax1.set_title(\"Driving fixed, \"+r'$f_{dr}=%0.2f$'%(0.0064*driving) + \" pN/nm\",fontsize=16,y=0.9)\n",
    "\n",
    "\n",
    "ax2.pcolormesh(XX_lp,YY_lp,ZZ_lp, cmap=plt.cm.Paired, alpha=0.2)\n",
    "ax2.scatter(X_lp[:,0],X_lp[:,1], c=y_lp, edgecolors='k', cmap=plt.cm.Paired)\n",
    "ax2.set_xlabel('Aspect Ratio',fontsize=15)\n",
    "ax2.set_ylabel('Driving (pN/nm)',fontsize=15)\n",
    "ticks = ticker.FuncFormatter(lambda y, pos: '{0:g}'.format(y*0.0064))\n",
    "ax2.yaxis.set_major_formatter(ticks)\n",
    "fig.tight_layout(pad=0,rect=(0.01,0.01,0.99,0.99))\n",
    "ax2.set_title(\"Per. length fixed, \"+r'$L_p = 25\\ \\mu$' + \"m\",fontsize=16,y=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ar_index = 1\n",
    "aspect_ratio2=60/1.5\n",
    "\n",
    "X_ar = np.array(df_fixed_ar2[['persistence_length','driving']])\n",
    "y_ar = np.array(df_fixed_ar2['spiral'])\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "def bounds(X,i):\n",
    "    return X[:, i].min() - .5, X[:, i].max() + .5\n",
    "\n",
    "\n",
    "x5_min, x5_max = bounds(X_ar,0)\n",
    "x6_min, x6_max = bounds(X_ar,1)\n",
    "\n",
    "XX_ar,YY_ar = np.meshgrid(np.linspace(x5_min,x5_max,100),np.linspace(x6_min,x6_max,100))\n",
    "ZZ_ar = logreg.predict(np.c_[XX_ar.ravel()/aspect_ratio2/1.5, YY_ar.ravel()*aspect_ratio2*1.5,np.ones(XX_ar.ravel().shape)*aspect_ratio2*1.5*1.5])\n",
    "ZZ_ar = ZZ_ar.reshape(XX_ar.shape)\n",
    "\n",
    "fig, ax0 = plt.subplots(1,1,figsize=(6,6),dpi=80)\n",
    "\n",
    "ax0.pcolormesh(XX_ar,YY_ar,ZZ_ar, cmap=plt.cm.Paired, alpha=0.2)\n",
    "ax0.scatter(X_ar[:,0],X_ar[:,1], c=y_ar, edgecolors='k', cmap=plt.cm.Paired)\n",
    "ax0.set_xlabel('Persistence Length (mm)',fontsize=15)\n",
    "ticks = ticker.FuncFormatter(lambda y, pos: '{0:g}'.format(y*25/1000/1000))\n",
    "ax0.xaxis.set_major_formatter(ticks)\n",
    "ax0.set_ylabel('Driving (pN/nm)',fontsize=15)\n",
    "ticks = ticker.FuncFormatter(lambda y, pos: '{0:g}'.format(y*0.0064))\n",
    "ax0.yaxis.set_major_formatter(ticks)\n",
    "ax0.set_title(\"Aspect ratio fixed, \"+r'$L/d = %.0f$'%(60/1.5),fontsize=16,y=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ar_index = 1\n",
    "feature_names = ['lp/len','len*dr']\n",
    "target_name = 'spiral'\n",
    "X = np.array(df_ar[ar_index][feature_names])\n",
    "y = np.array(df_ar[ar_index][target_name])\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "#poly = PolynomialFeatures(2,False,False)\n",
    "#X=poly.fit_transform(X)\n",
    "param_grid = dict(penalty=[\"l1\",'l2'],C=[1,10,100,1000,10000,1e5,1e6,1e7,1e8])\n",
    "grid = GridSearchCV(logreg, param_grid, cv=10, scoring='accuracy')\n",
    "grid.fit(X,y)\n",
    "print(\"Best logistic regression accuracy: \" + str(grid.best_score_))\n",
    "best = grid.best_params_\n",
    "print(\"Best parameters: \" + str(best))\n",
    "logreg = LogisticRegression(penalty=best['penalty'],C=best['C'],max_iter=200)\n",
    "logreg.fit(X,y)\n",
    "coeff = logreg.coef_[0]\n",
    "intercept = logreg.intercept_[0]\n",
    "print(\"Coeffs: \" + str(coeff))\n",
    "print(\"Intercept: \" + str(intercept))\n",
    "print(\"Aspect Ratio: \" + str(aspect_ratio[ar_index]))\n",
    "print(str(coeff[0]) + \" Lp/L + \" + str(coeff[1]) + \" F_dr + \" + str(intercept) + \" = 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the decision boundary surface\n",
    "pts = 100 # num mesh points\n",
    "# Set limits for our three parameters\n",
    "x1_min, x1_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "x2_min, x2_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "XX = np.linspace(x1_min,x1_max,pts)\n",
    "YY = - ( intercept + coeff[0] * XX) / coeff[1]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(XX,YY)\n",
    "\n",
    "# Plot the training points\n",
    "ax = plt.gca()\n",
    "ax.scatter(X[:, 0], X[:, 1], c=-y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "#ax.scatter(X[0,0],X[0,1],X[0,2],c='k',edgecolors='k')\n",
    "#print(y[0])\n",
    "ax.set_xlabel(r'$L_p/L$ ' + \"ratio\")\n",
    "ax.set_ylabel(r'Driving Force')\n",
    "#ax.set_zlabel(\"Aspect Ratio\")\n",
    "ax.set_xlim(x1_min,x1_max)\n",
    "ax.set_ylim(x2_min,x2_max)\n",
    "#ax.set_zlim(x3_min,x3_max)\n",
    "ax.set_title('Spool Success (blue) vs Failure (red) at T=0')#,y=0.1)\n",
    "ax.title.set_fontsize(20)\n",
    "ax.xaxis.label.set_fontsize(15)\n",
    "ax.yaxis.label.set_fontsize(15)\n",
    "#ax.zaxis.label.set_fontsize(15)\n",
    "#plt.legend(['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "60*0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "9.6*25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "240/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "10 * 0.16 * 25 / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kinesin_force = 6 # pN, force generated by single kinesin\n",
    "binding_site_density = 0.4 # sites/nm, maximum binding density of MT (for all 13 protofilaments)\n",
    "bound_protofilament_fraction = 3.0/13 # estimate of how many protofilaments out of 13 can be bound by gliding MT\n",
    "sigma = 25 # nm, simulation unit length\n",
    "driving_unit = 0.16 # pN/nm, simulation unit force per unit length\n",
    "kinesin_force*binding_site_density*bound_protofilament_fraction*sigma*driving_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "4.6/0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "6 *0.4/13.0*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.4/13.0*3*25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2.3 * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "13.8/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "3.5*0.16*100*25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.55/0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "200**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "100/np.log(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = lambda x: x/np.log(x)\n",
    "x = np.linspace(20,100,100)\n",
    "plt.figure()\n",
    "plt.plot(x,y(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_seglength=df_seglength[df_seglength.persistence_length != 1000]\n",
    "df_seglength=df_seglength[df_seglength.child_length > 2.28]\n",
    "cl_group=df_seglength.groupby('child_length')\n",
    "fig, ax = plt.subplots(nrows=len(cl_group), ncols=1,figsize=(3,30))\n",
    "mmap = {0:'x',1:'o'}\n",
    "ccmap = {0:'r',1:'b'}\n",
    "index=0\n",
    "slopes=[]\n",
    "cls=[]\n",
    "for cl,group1 in cl_group:\n",
    "    pl_group=group1.groupby('persistence_length')\n",
    "    ax[index].set_title('Spool success, $l_{bond}=%2.2f$'%cl)\n",
    "    ax[index].set_ylabel('$L_p$')\n",
    "    ax[index].set_xlabel('$f_{dr}$')\n",
    "    feature_names = ['persistence_length','driving']\n",
    "    target_name = 'spiral'\n",
    "    X = np.array(group1[feature_names])\n",
    "    y = np.array(group1[target_name])\n",
    "    logreg = LogisticRegression(max_iter=200)\n",
    "    param_grid = dict(penalty=[\"l1\"],C=[1,10,100,1000,1e4])\n",
    "    grid = GridSearchCV(logreg, param_grid, cv=10, scoring='accuracy')\n",
    "    grid.fit(X,y)\n",
    "    best = grid.best_params_\n",
    "    logreg = LogisticRegression(penalty=best['penalty'],C=best['C'],max_iter=200)\n",
    "    logreg.fit(X,y)\n",
    "    coeff = logreg.coef_[0]\n",
    "    intercept = logreg.intercept_\n",
    "    xx=np.linspace(0,20,10)\n",
    "    yy=lambda xx: - ( intercept + coeff[1] * xx) / coeff[0]\n",
    "    slopes.append(coeff[1]/coeff[0])\n",
    "    cls.append(cl)\n",
    "    ax[index].plot(xx,yy(xx))\n",
    "    ax[index].set_ylim(100,900)\n",
    "    for pl,group2 in pl_group:\n",
    "        group2['spiral_marker']=group2['spiral'].apply(lambda y: 'X' if y==0 else 'o')\n",
    "        for spool_success,group3 in group2.groupby('spiral'):\n",
    "            ax[index].scatter(x=group3['driving'],y=group3['persistence_length'],marker=mmap[spool_success],c=ccmap[spool_success])\n",
    "    index+=1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slopes = [-i for i in slopes]\n",
    "plt.figure()\n",
    "plt.title('Convergence at small bond length')\n",
    "plt.ylabel('Slope of spool success decision boundary')\n",
    "plt.xlabel('Bond length ($\\sigma$)')\n",
    "plt.plot(cls,slopes,'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "masterDF = pd.read_pickle('spiral_t0.pkl')\n",
    "coeffs={}\n",
    "lengths = masterDF.length.unique()\n",
    "for length in lengths:\n",
    "    df = masterDF[masterDF.length==length]\n",
    "    df['persistence_length/length']=df['persistence_length']/df['length']\n",
    "    df['driving_force']=df['driving']*df['length']\n",
    "    feature_names = ['persistence_length/length','driving_force']\n",
    "    target_name = 'spiral'\n",
    "    X = np.array(df[feature_names])\n",
    "    y = np.array(df[target_name])\n",
    "    #logreg = LogisticRegression(max_iter=1000)\n",
    "    #param_grid = dict(penalty=[\"l1\",'l2'],C=[1,10,100,1000,10000,1e5,1e6,1e7,1e8])\n",
    "    #grid = GridSearchCV(logreg, param_grid, cv=3, scoring='accuracy')\n",
    "    #grid.fit(X,y)\n",
    "    #best = grid.best_params_\n",
    "    logreg = LogisticRegression(penalty='l1',C=1,max_iter=500)\n",
    "    logreg.fit(X,y)\n",
    "    coeff = logreg.coef_[0]\n",
    "    intercept = logreg.intercept_[0]\n",
    "    coef=-coeff[0]/coeff[1]\n",
    "    intercpt = intercept/coeff[1]\n",
    "    coeffs[length]=(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(coeffs.keys(),coeffs.values(),'k-')\n",
    "plt.xlabel(\"L/d\")\n",
    "plt.ylabel(\"Critical flexure number\")\n",
    "plt.title(\"Critical flexure number as a function of aspect ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are interested in $F_{dr} = C \\frac{L_p}{L^2 d}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for length in lengths:\n",
    "    fig=plt.figure()\n",
    "    #aax=fig.gca()\n",
    "    #length=200\n",
    "    coef = coeffs[length]\n",
    "    df = masterDF[masterDF.length==length]\n",
    "    df['persistence_length/length']=df['persistence_length']/df['length']\n",
    "    L = df.length.mean()\n",
    "    d = 1\n",
    "    C = 2.25*np.pi**2\n",
    "    mmap = {0:'x',1:'o'}\n",
    "    ccmap = {0:'r',1:'b'}\n",
    "    x=np.linspace(df['persistence_length/length'].min(),df['persistence_length/length'].max(),10)\n",
    "    fit = lambda x: coef[1]*x\n",
    "    #C = d*L**2/coef\n",
    "    #theory = lambda x: d*L**2*x/C\n",
    "    plt.plot(x,fit(x),'k--')\n",
    "    #plt.plot(x,theory(x),'g-.')\n",
    "    plt.title(\"Spool failure (red) vs success (blue) with filament length L=\"+str(L))\n",
    "    plt.ylabel(\"Driving force density\")\n",
    "    plt.xlabel(\"Persistence length/Length\")\n",
    "    plt.ylim(df['driving'].min(),df['driving'].max())\n",
    "    for spool_success,df in df.groupby('spiral'):\n",
    "        plt.scatter(x=df['persistence_length/length'],y=df['driving'],marker=mmap[spool_success],c=ccmap[spool_success])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "masterDF.length.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C/np.pi**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "100/5.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "19.37/(np.pi**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.length.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.length.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.persistence_length/df.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
